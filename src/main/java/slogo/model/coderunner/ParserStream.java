package slogo.model.coderunner;

import java.util.ArrayList;
import java.util.List;
import slogo.model.api.exception.coderunner.ErrorType;
import slogo.model.api.exception.coderunner.RunCodeError;
import slogo.model.coderunner.Expression.Block;
import slogo.model.coderunner.Expression.Make;

/**
 * Parses a stream of tokens into a stream of interpretable expressions.
 *
 * @author Jason Qiu
 */
class ParserStream implements Parser {

  /**
   * Initializes the parser stream
   *
   * @param lexer the input token stream
   */
  ParserStream(Lexer lexer) {
    this.lexer = lexer;
    previousToken = null;
    currentToken = null;
    nextToken();
  }

  private static final String TOKEN_LINE_PLACEHOLDER = "autogenerated by parser";

  /**
   * Attempts to parse the next expression from a given token stream
   *
   * @return the expression if successful, otherwise null
   * @throws RunCodeError if there were parsing errors
   */
  @Override
  public Expression parseNext() throws RunCodeError {
    return expression();
  }

  private Expression expression() {
    return term();
  }

  private Expression term() {
    Expression expression = factor();
    if (match(TokenType.PLUS, TokenType.MINUS)) {
      Token operator = previousToken;
      Expression right = factor();
      return new Expression.Binary(operator, expression, right);
    }
    return expression;
  }

  private Expression factor() {
    Expression expression = comparison();
    if (match(TokenType.STAR, TokenType.FORWARD_SLASH, TokenType.PERCENT)) {
      Token operator = previousToken;
      Expression right = comparison();
      return new Expression.Binary(operator, expression, right);
    }
    return expression;
  }

  private Expression comparison() {
    Expression expression = unary();
    if (match(TokenType.EQUAL_TO, TokenType.NOT_EQUAL_TO, TokenType.GREATER_EQUAL_TO,
        TokenType.LESS_EQUAL_TO, TokenType.GREATER_THAN, TokenType.LESS_THAN)) {
      Token operator = previousToken;
      Expression right = unary();
      return new Expression.Binary(operator, expression, right);
    }
    return expression;
  }

  private Expression unary() {
    Expression expression = literal();
    if (expression != null) {
      return expression;
    }
    if (match(TokenType.TILDA)) {
      return new Expression.Unary(previousToken, literal());
    }
    return expression;
  }

  private Expression literal() {
    Expression expression = keywords();
    if (expression != null) {
      return expression;
    }
    if (match(TokenType.VARIABLE)) {
      return new Expression.Variable(previousToken);
    }
    if (match(TokenType.NUMBER)) {
      return new Expression.Number((double) previousToken.literal());
    }
    return expression;
  }

  // keywords expressions
  // MAKE, REPEAT, DOTIMES, FOR, IF, IFELSE, TO, ID, TURTLES, TELL, ASK, ASKWITH
  private Expression keywords() {
    Block expression = block();

    if (match(TokenType.MAKE)) {
      return makeExpression();
    }
    if (match(TokenType.REPEAT)) {
      return repeatExpression();
    }
    if (match(TokenType.DOTIMES)) {
      return doTimesExpression();
    }
    if (match(TokenType.FOR)) {
      return forExpression();
    }
    if (match(TokenType.IF)) {
      return ifExpression();
    }
    if (match(TokenType.IFELSE)) {
      return ifElseExpression();
    }
    if (match(TokenType.TO)) {
      return toExpression();
    }
    if (match(TokenType.TURTLES)) {
      return new Expression.Turtles();
    }
    if (match(TokenType.TELL)) {
      return new Expression.Tell(consumeBlock().getBody());
    }
    if (match(TokenType.ASK)) {
      return new Expression.Ask(consumeBlock().getBody(), consumeBlock());
    }
    if (match(TokenType.ASKWITH)) {
      return new Expression.AskWith(expression(), consumeBlock());
    }
    if (match(TokenType.COMMAND)) {
      return new Expression.Call(previousToken);
    }

    return expression;
  }

  private Expression makeExpression() {
    Token variable = consume(TokenType.VARIABLE);
    Expression value = expression();
    return new Make(variable, value);
  }

  private Expression repeatExpression() {
    Expression times = expression();
    Block body = consumeBlock();
    Token plusToken = new Token(TokenType.PLUS, null, -1, TOKEN_LINE_PLACEHOLDER);
    Expression end = new Expression.Binary(plusToken, times, new Expression.Number(1));
    return new Expression.For(new Token(TokenType.VARIABLE, "repcount", -1, TOKEN_LINE_PLACEHOLDER),
        new Expression.Number(1), end, new Expression.Number(1), body);
  }

  private Expression doTimesExpression() {
    consume(TokenType.LEFT_SQUARE_BRACKET);
    consume(TokenType.VARIABLE);
    Token variableToken = previousToken;
    Expression limit = expression();
    consume(TokenType.RIGHT_SQUARE_BRACKET);

    Block body = consumeBlock();

    Token plusToken = new Token(TokenType.PLUS, null, -1, TOKEN_LINE_PLACEHOLDER);
    Expression end = new Expression.Binary(plusToken, limit, new Expression.Number(1));
    return new Expression.For(variableToken, new Expression.Number(1), end,
        new Expression.Number(1), body);
  }

  private Expression forExpression() {
    consume(TokenType.LEFT_SQUARE_BRACKET);
    consume(TokenType.VARIABLE);
    Token variableToken = previousToken;
    Expression start = expression();
    Expression end = expression();
    Expression increment = expression();
    consume(TokenType.RIGHT_SQUARE_BRACKET);

    Block body = consumeBlock();

    return new Expression.For(variableToken, start, end, increment, body);
  }

  private Expression ifExpression() {
    Expression predicate = blockUntil(TokenType.LEFT_SQUARE_BRACKET);
    Expression trueBranch = consumeBlock();
    return new Expression.IfElse(predicate, trueBranch, null);
  }

  private Expression ifElseExpression() {
    Expression predicate = blockUntil(TokenType.LEFT_SQUARE_BRACKET);
    Expression trueBranch = consumeBlock();
    Expression falseBranch = consumeBlock();
    return new Expression.IfElse(predicate, trueBranch, falseBranch);
  }

  private Expression toExpression() {
    consume(TokenType.COMMAND);
    Token commandName = previousToken;
    List<Token> parameters = new ArrayList<>();
    consume(TokenType.LEFT_SQUARE_BRACKET);
    while (match(TokenType.VARIABLE)) {
      parameters.add(previousToken);
    }
    consume(TokenType.RIGHT_SQUARE_BRACKET);
    Block body = consumeBlock();

    return new Expression.To(commandName, parameters, body);
  }

  private Block blockUntil(TokenType limiter) {
    List<Expression> body = new ArrayList<>();
    while (!check(limiter)) {
      body.add(expression());
    }
    return new Block(body, previousToken.line());
  }

  private Block block() {
    if (match(TokenType.LEFT_SQUARE_BRACKET)) {
      List<Expression> body = new ArrayList<>();
      while (!match(TokenType.RIGHT_SQUARE_BRACKET)) {
        body.add(expression());
      }
      return new Block(body, previousToken.line());
    }
    return null;
  }

  private Block consumeBlock() {
    consume(TokenType.LEFT_SQUARE_BRACKET);
    List<Expression> body = new ArrayList<>();
    while (!check(TokenType.RIGHT_SQUARE_BRACKET)) {
      body.add(expression());
    }
    consume(TokenType.RIGHT_SQUARE_BRACKET);
    return new Block(body, previousToken.line());
  }

  private boolean check(TokenType... types) {
    for (TokenType type : types) {
      if (currentToken.type() == type) {
        return true;
      }
    }
    return false;
  }

  private Token consume(TokenType type) {
    if (!match(type)) {
      throw ErrorFactory.createError(ErrorType.PARSE, "expectedDifferentToken", currentToken);
    }
    return previousToken;
  }

  private boolean match(TokenType... types) {
    for (TokenType type : types) {
      if (currentToken.type() == type) {
        nextToken();
        return true;
      }
    }
    return false;
  }

  private boolean isAtEnd() {
    return previousToken != null && previousToken.type() == TokenType.EOF;
  }

  private Token nextToken() {
    previousToken = currentToken;
    currentToken = lexer.nextToken();
    if (isAtEnd()) {
      throw ErrorFactory.createError(ErrorType.PARSE, "expectedTokens", currentToken);
    }
    return currentToken;
  }

  private final Lexer lexer;
  private Token previousToken;
  private Token currentToken;
}
